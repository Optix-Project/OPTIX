{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"6IGlv7k8xG4zaAfQhDII\")\n",
        "project = rf.workspace(\"wenchuan-wu\").project(\"t2_glass\")\n",
        "dataset = project.version(2).download(\"tensorflow\")\n"
      ],
      "metadata": {
        "id": "4vPPPi7oSFAb",
        "outputId": "06655bb5-03a6-482d-e9d3-fe2b27ba95f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: roboflow in /usr/local/lib/python3.10/dist-packages (1.1.9)\n",
            "Requirement already satisfied: certifi==2023.7.22 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2023.7.22)\n",
            "Requirement already satisfied: chardet==4.0.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.0.0)\n",
            "Requirement already satisfied: cycler==0.10.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (0.10.0)\n",
            "Requirement already satisfied: idna==2.10 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.10)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.4.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.23.5)\n",
            "Requirement already satisfied: opencv-python-headless==4.8.0.74 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.8.0.74)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from roboflow) (9.4.0)\n",
            "Requirement already satisfied: pyparsing==2.4.7 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.8.2)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.0.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.31.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.16.0)\n",
            "Requirement already satisfied: supervision in /usr/local/lib/python3.10/dist-packages (from roboflow) (0.16.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.0.7)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.66.1)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (6.0.1)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.0.0)\n",
            "Requirement already satisfied: python-magic in /usr/local/lib/python3.10/dist-packages (from roboflow) (0.4.27)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (1.2.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (4.44.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (23.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->roboflow) (3.3.2)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from supervision->roboflow) (1.11.3)\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in T2_Glass-2 to tensorflow:: 100%|██████████| 11016/11016 [00:01<00:00, 8934.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to T2_Glass-2 in tensorflow:: 100%|██████████| 529/529 [00:00<00:00, 4781.33it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save the image paths and their corresponding labels in a CSV file.\n",
        "\n"
      ],
      "metadata": {
        "id": "OFMLGx4_bFfX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Image data is in a directory called 'images'\n",
        "image_dir = 'Glasses-and-No-Glasses-1'\n",
        "\n",
        "# Get all the image paths in the directory\n",
        "image_paths = []\n",
        "for dirpath, dirnames, filenames in os.walk(image_dir):\n",
        "    for filename in filenames:\n",
        "        if filename.endswith('.jpg') or filename.endswith('.png'):\n",
        "            image_paths.append(os.path.join(dirpath, filename))\n",
        "\n",
        "# Get the image labels based on the directory names\n",
        "image_labels = [os.path.basename(os.path.dirname(image_path)) for image_path in image_paths]\n",
        "\n",
        "# Create a dataframe with the image paths and their corresponding labels\n",
        "df = pd.DataFrame({'image': image_paths, 'label': image_labels})\n",
        "\n",
        "# Save the dataframe to a CSV file\n",
        "df.to_csv('image_data.csv', index=False)"
      ],
      "metadata": {
        "id": "sqexk-S3bHsH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CREATE MODEL"
      ],
      "metadata": {
        "id": "rF_q-lPybVxZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Import Library\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "WuL9Z3kUbZn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data (dataset is in CSV format with 'image' and 'label' columns)\n",
        "data = pd.read_csv('image_data.csv')"
      ],
      "metadata": {
        "id": "hzrutdvjZu_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create image directory\n",
        "os.makedirs('images', exist_ok=True)"
      ],
      "metadata": {
        "id": "0SBhvWLTbxD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save images from the dataset\n",
        "for i, row in data.iterrows():\n",
        "    with open(os.path.join('images', str(i) + '.jpg'), 'wb') as f:\n",
        "        f.write(row['image'])\n",
        "\n",
        "# Define image directory, size, and format\n",
        "image_dir = 'images'\n",
        "image_size = (150, 150)\n",
        "image_format = 'jpg'"
      ],
      "metadata": {
        "id": "P0WITup9cEEC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the function to load data\n",
        "def load_data(image_dir, image_size, image_format):\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True)\n",
        "\n",
        "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "    train_generator = train_datagen.flow_from_directory(\n",
        "        image_dir,\n",
        "        target_size=image_size,\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')\n",
        "\n",
        "    test_generator = test_datagen.flow_from_directory(\n",
        "        image_dir,\n",
        "        target_size=image_size,\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')\n",
        "\n",
        "    return train_generator, test_generator"
      ],
      "metadata": {
        "id": "ZRFEVzehcJle"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the train and test datasets\n",
        "train_generator, test_generator = load_data(image_dir, image_size, image_format)"
      ],
      "metadata": {
        "id": "j6DtJ_T3cL76"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape the images\n",
        "train_images = train_generator.next()[0].reshape(10000, 150, 150, 3)\n",
        "test_images = test_generator.next()[0].reshape(2500, 150, 150, 3)\n",
        "\n",
        "# Reshape the labels\n",
        "train_labels = train_generator.next()[1]\n",
        "test_labels = test_generator.next()[1]"
      ],
      "metadata": {
        "id": "yikkGB-VcOy8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate Accuracy Model"
      ],
      "metadata": {
        "id": "MBMOYPG9ckM5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "# Define the model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_images, train_labels, epochs=25, validation_data=(test_images, test_labels))\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "loss, accuracy = model.evaluate(test_images, test_labels)\n",
        "print('Test accuracy:', accuracy)"
      ],
      "metadata": {
        "id": "xmPN9snbcnK2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To test on virtual glasses, you need to provide a pair of virtual glasses images. The input image will be passed through the model to obtain the predictions."
      ],
      "metadata": {
        "id": "_2Xm5H3pZ-G-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_image(file_path):\n",
        "    img = load_img(file_path, target_size=(150, 150))\n",
        "    img = img_to_array(img)\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "\n",
        "    prediction = model.predict(img)\n",
        "\n",
        "    return np.argmax(prediction)\n",
        "\n",
        "print(test_image('path_to_image.jpg'))"
      ],
      "metadata": {
        "id": "wCoPhcaMaBdQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SAVE MODEL"
      ],
      "metadata": {
        "id": "UiGJYEvUdM7I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# save the model\n",
        "model.save('my_model.h5')\n",
        "\n",
        "# load the saved model\n",
        "loaded_model = load_model('my_model.h5')"
      ],
      "metadata": {
        "id": "j1jTbuQFdLut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try on virtual glasses using the camera model"
      ],
      "metadata": {
        "id": "rHJjBmFndxmI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model"
      ],
      "metadata": {
        "id": "JNlHMaoedzKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model('model.h5')"
      ],
      "metadata": {
        "id": "fqdZ7na4d5bZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cap = cv2.VideoCapture(0)"
      ],
      "metadata": {
        "id": "nmdFRrmad71S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image(frame):\n",
        "    # Preprocessing steps\n",
        "    while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "    preprocessed_frame = preprocess_image(frame)\n",
        "    prediction = model.predict(preprocessed_frame)\n",
        "    # Blending and displaying the predicted virtual glasses frame\n",
        "    return frame"
      ],
      "metadata": {
        "id": "ZdVy0c9Od_qx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Release the camera\n",
        "cap.release()"
      ],
      "metadata": {
        "id": "rxU167tOeB-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Close Program\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "bvBFuWIdeL7R"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}